{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801a491b-5687-4107-8ea1-04e09d2ce930",
   "metadata": {},
   "source": [
    "## Tensor Operations:\n",
    "A tensor is a multi-dimensional array, similar to a NumPy array.\n",
    "In PyTorch, tensors can be created using the torch.Tensor class.\n",
    "Basic tensor operations like addition, subtraction, multiplication, and division can be performed using the standard arithmetic operators +, -, *, /.\n",
    "Here are some short exercises to help you get started:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d333a049-c63b-4170-a466-0d796f65d33d",
   "metadata": {},
   "source": [
    "### Exercise 1: Creating Tensors\n",
    "Create a 2x3 tensor filled with zeros and a 3x2 tensor filled with ones using PyTorch. Print the tensors to verify that they are created correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50bd108a-890f-416d-b400-6710456d4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c826ade2-daa5-42c9-b829-f4cbde09dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2, 6, 4, 4, 1, 3],\n",
      "        [6, 0, 4, 1, 1, 7],\n",
      "        [0, 5, 7, 8, 1, 5],\n",
      "        [6, 7, 1, 3, 1, 3]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2x3 tensor filled with zeros\n",
    "zeros_tensor = torch.zeros(2, 3)\n",
    "print(zeros_tensor)\n",
    "\n",
    "# Create a 3x2 tensor filled with ones\n",
    "ones_tensor = torch.ones(3, 2)\n",
    "print(ones_tensor)\n",
    "\n",
    "rand_tensor = torch.randint(0, 9, (4,6))\n",
    "print(rand_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907fd5d7-8b39-4789-8593-7eb159227de9",
   "metadata": {},
   "source": [
    "### Exercise 2: Performing Basic Tensor Operations\n",
    "Perform basic tensor operations using PyTorch. Create two tensors of the same shape and perform addition, subtraction, multiplication, and division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fa3e31-d2c5-4dcd-ab81-58055cfeac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "tensor([[-4, -4],\n",
      "        [-4, -4]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors of the same shape\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Perform addition\n",
    "c = a + b\n",
    "print(c)\n",
    "\n",
    "# Perform subtraction\n",
    "d = a - b\n",
    "print(d)\n",
    "\n",
    "# Perform multiplication\n",
    "e = a * b\n",
    "print(e)\n",
    "\n",
    "# Perform division\n",
    "f = a / b\n",
    "print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc04b1-c7a9-4857-acb7-67a6bece11dc",
   "metadata": {},
   "source": [
    "## Automatic Differentiation:\n",
    "- Learn about automatic differentiation, a key feature of PyTorch that makes it easy to compute gradients for optimization\n",
    "- Understand the basics of backpropagation, which is used to train deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ecaf5-5951-4c76-b326-0247a67f98cc",
   "metadata": {},
   "source": [
    "## Building Neural Networks:\n",
    "- Learn how to build neural networks using PyTorch's nn module\n",
    "    - PyTorch's nn module makes it easy to construct and train neural networks. The basic idea is to define a neural network as a sequence of layers, where each layer performs a specific computation on the input data. PyTorch provides several types of layers, such as linear layers, convolutional layers, and recurrent layers, as well as various activation functions that can be used between the layers to introduce nonlinearity into the model.\n",
    "    - A simple example of building a neural network with PyTorch's nn module might involve defining a network architecture with a few layers (e.g., fully connected layers, convolutional layers, etc.) and specifying the activation functions to use between each layer. Here's a basic example:\n",
    "- Understand the different types of layers and activation functions used in neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60095ff7-7a1d-4e04-b970-3cecfe94efb6",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e0ece4-2273-4f4b-8ddb-880f8fb44c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network with one hidden layer\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the neural network\n",
    "net = MyNet(input_size=10, hidden_size=20, output_size=1)\n",
    "\n",
    "# Apply the neural network to some input data\n",
    "x = torch.randn(32, 10)\n",
    "y = net(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e739a8f-34cb-44dc-bf92-61c7f41bea28",
   "metadata": {},
   "source": [
    "In this example, we define a neural network with one hidden layer using PyTorch's nn module. The __init__ method initializes the layers of the network, and the forward method defines how the input data is transformed as it passes through the network. We also instantiate the neural network and apply it to some random input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b00cf1d-6c9d-4512-b6d1-8e8b053762d8",
   "metadata": {},
   "source": [
    "Here are some exercises you can try to build your understanding of building neural networks in PyTorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72a818-70ca-4aa6-88df-8b48a4b12721",
   "metadata": {},
   "source": [
    "1. Define a neural network with two hidden layers using the nn module.\n",
    "- Use the ReLU activation function for the hidden layers and the sigmoid activation function for the output layer.\n",
    "- Make the network input size 784 (for images in the MNIST dataset),\n",
    "    - the first hidden layer size 256\n",
    "    - the second hidden layer size 128\n",
    "    - the output layer size 10 (for the 10 possible digit classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4321ec36-1524-4ab0-9996-9d9aa3906f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network with two hidden layers\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.hidden1 = nn.Linear(784, 256)\n",
    "        self.hidden2 = nn.Linear(256, 128)\n",
    "        self.output = nn.Linear(128, 10)\n",
    "\n",
    "    #The forward method is called internally for the MyNet class by the __call__ method.\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the neural network\n",
    "net = MyNet()\n",
    "\n",
    "# Apply the neural network to some input data\n",
    "x = torch.randn(32, 784)\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3577530-42f8-4626-bd6b-85eafe7ad64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4988, 0.4841, 0.4792, 0.5236, 0.4730, 0.5306, 0.5206, 0.5241, 0.5200,\n",
       "         0.4922],\n",
       "        [0.5019, 0.4898, 0.4670, 0.5216, 0.4418, 0.5075, 0.5114, 0.4935, 0.4842,\n",
       "         0.5059],\n",
       "        [0.5228, 0.4733, 0.4533, 0.4939, 0.4796, 0.5236, 0.4765, 0.5052, 0.5030,\n",
       "         0.4994],\n",
       "        [0.4871, 0.4741, 0.4725, 0.5020, 0.4317, 0.5002, 0.4670, 0.5020, 0.4989,\n",
       "         0.4849],\n",
       "        [0.4935, 0.4819, 0.4665, 0.4987, 0.4663, 0.4736, 0.5441, 0.5287, 0.4526,\n",
       "         0.4820],\n",
       "        [0.5296, 0.5170, 0.4890, 0.5054, 0.4644, 0.5075, 0.4922, 0.5117, 0.4817,\n",
       "         0.4970],\n",
       "        [0.4833, 0.5151, 0.4751, 0.4924, 0.4689, 0.5169, 0.5132, 0.5237, 0.4776,\n",
       "         0.4885],\n",
       "        [0.4987, 0.4947, 0.4921, 0.5055, 0.4634, 0.5072, 0.5100, 0.5302, 0.4868,\n",
       "         0.4762],\n",
       "        [0.5116, 0.4906, 0.4640, 0.5035, 0.4683, 0.5267, 0.5075, 0.4731, 0.5155,\n",
       "         0.4875],\n",
       "        [0.5169, 0.4787, 0.4783, 0.5018, 0.4987, 0.5185, 0.5126, 0.4989, 0.4947,\n",
       "         0.4634],\n",
       "        [0.4924, 0.5225, 0.4940, 0.5046, 0.4151, 0.5073, 0.5217, 0.5141, 0.4647,\n",
       "         0.4789],\n",
       "        [0.5019, 0.4961, 0.4787, 0.5147, 0.4701, 0.5156, 0.4747, 0.5195, 0.4971,\n",
       "         0.4925],\n",
       "        [0.4920, 0.4887, 0.4674, 0.5243, 0.4288, 0.5258, 0.5325, 0.5299, 0.4807,\n",
       "         0.4979],\n",
       "        [0.5171, 0.4914, 0.4768, 0.5016, 0.4604, 0.4994, 0.5162, 0.4841, 0.5343,\n",
       "         0.4419],\n",
       "        [0.5209, 0.5128, 0.4845, 0.5045, 0.4462, 0.5166, 0.4925, 0.4686, 0.5265,\n",
       "         0.5115],\n",
       "        [0.4979, 0.4603, 0.4692, 0.4868, 0.5104, 0.4944, 0.5321, 0.5214, 0.4795,\n",
       "         0.4504],\n",
       "        [0.5021, 0.4860, 0.4774, 0.5174, 0.4831, 0.5301, 0.5021, 0.5222, 0.4978,\n",
       "         0.5029],\n",
       "        [0.5169, 0.4899, 0.4715, 0.4793, 0.4341, 0.5148, 0.4882, 0.5168, 0.4797,\n",
       "         0.4931],\n",
       "        [0.5063, 0.4970, 0.4570, 0.5117, 0.4721, 0.5138, 0.5385, 0.5182, 0.5151,\n",
       "         0.5037],\n",
       "        [0.5055, 0.5461, 0.4607, 0.4724, 0.4450, 0.5130, 0.4773, 0.5130, 0.4896,\n",
       "         0.4857],\n",
       "        [0.5314, 0.5139, 0.4776, 0.5067, 0.4116, 0.5029, 0.5168, 0.5091, 0.5373,\n",
       "         0.5219],\n",
       "        [0.5080, 0.5175, 0.4950, 0.5104, 0.4471, 0.5113, 0.5041, 0.4840, 0.5360,\n",
       "         0.4854],\n",
       "        [0.5014, 0.5223, 0.4863, 0.5351, 0.4716, 0.4932, 0.5260, 0.4991, 0.5246,\n",
       "         0.5137],\n",
       "        [0.5013, 0.5177, 0.4753, 0.4894, 0.4667, 0.5172, 0.5180, 0.5162, 0.5030,\n",
       "         0.4523],\n",
       "        [0.5166, 0.5054, 0.4782, 0.5466, 0.4760, 0.4991, 0.5193, 0.5237, 0.4712,\n",
       "         0.5060],\n",
       "        [0.5183, 0.5063, 0.4696, 0.5044, 0.4762, 0.5243, 0.5258, 0.4964, 0.5036,\n",
       "         0.4774],\n",
       "        [0.5169, 0.4904, 0.4833, 0.5378, 0.4586, 0.5016, 0.5093, 0.5076, 0.4929,\n",
       "         0.4879],\n",
       "        [0.4914, 0.5013, 0.4716, 0.4959, 0.4659, 0.5138, 0.5166, 0.4947, 0.5244,\n",
       "         0.5159],\n",
       "        [0.5125, 0.4694, 0.4650, 0.5186, 0.4664, 0.5236, 0.5020, 0.5143, 0.4985,\n",
       "         0.4847],\n",
       "        [0.5111, 0.4947, 0.4890, 0.4827, 0.4624, 0.5283, 0.4983, 0.5124, 0.4866,\n",
       "         0.5052],\n",
       "        [0.4938, 0.5032, 0.4775, 0.5307, 0.4557, 0.5131, 0.5235, 0.5427, 0.5037,\n",
       "         0.4807],\n",
       "        [0.4930, 0.4975, 0.4819, 0.5110, 0.4964, 0.5241, 0.4809, 0.5188, 0.4899,\n",
       "         0.5002]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1ec26-fc55-4df6-b886-d3c140c2da79",
   "metadata": {},
   "source": [
    "2. Define a neural network with a convolutional layer followed by two fully connected layers using the nn module. \n",
    "- Use the ReLU activation function for the hidden layers and the softmax activation function for the output layer. \n",
    "- Make the convolutional layer have 10 output channels, a kernel size of 5, and a stride of 1. \n",
    "- Make the first fully connected layer have 100 output units and the second fully connected layer have 10 output units (for the 10 possible digit classes in MNIST)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec5b94-0df0-4906-a337-5679ee1970c1",
   "metadata": {},
   "source": [
    "## Training Neural Networks:\n",
    "- Learn how to train a neural network using PyTorch's autograd and optim modules\n",
    "- Understand the concepts of loss functions, optimization algorithms, and learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83da25-5846-4e9c-839f-8705c149a570",
   "metadata": {},
   "source": [
    "## Data Loading:\n",
    "- Learn how to load and preprocess data using PyTorch's DataLoader and transforms modules\n",
    "- Understand how to prepare data for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f078b9d-cbe5-4f44-b51b-c765281c5d42",
   "metadata": {},
   "source": [
    "## Model Evaluation:\n",
    "- Learn how to evaluate the performance of a trained model on a test set\n",
    "- Understand the concepts of accuracy, precision, and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e20a9-860d-4fdf-9e33-b156d5dca09c",
   "metadata": {},
   "source": [
    "## Advanced Topics:\n",
    "- Learn about advanced topics:\n",
    "    - convolutional neural networks\n",
    "    - recurrent neural networks\n",
    "    - transfer learning\n",
    "- Understand how to use PyTorch for tasks:\n",
    "    - image classification\n",
    "    - natural language processing\n",
    "    - reinforcement learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
